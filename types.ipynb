{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c337cc-590d-4522-8f48-955da9ca002b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/09 12:15:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.179:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>column_rows</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1146f9a10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\"types\").getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593a3d2a-cf6a-4875-8e5d-7c954bd434b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+----------------+--------------------+-----+\n",
      "|    Player Name|Season|       Statistic|            Variable|Value|\n",
      "+---------------+------+----------------+--------------------+-----+\n",
      "|Robert Garrigus|  2010|Driving Distance|Driving Distance ...|   71|\n",
      "|   Bubba Watson|  2010|Driving Distance|Driving Distance ...|   77|\n",
      "| Dustin Johnson|  2010|Driving Distance|Driving Distance ...|   83|\n",
      "|Brett Wetterich|  2010|Driving Distance|Driving Distance ...|   54|\n",
      "|    J.B. Holmes|  2010|Driving Distance|Driving Distance ...|  100|\n",
      "+---------------+------+----------------+--------------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/09 12:15:54 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "path = \"datasets/\"\n",
    "students = spark.read.csv(path+\"students.csv\", inferSchema=True, header=True)\n",
    "tour = spark.read.csv(path+\"pga_tour_historical.csv\", inferSchema=True, header=True)\n",
    "tour.limit(100).dropna().dropDuplicates().limit(5).show()\n",
    "students.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaddf03-8726-4932-98c8-978716846799",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.DataType\n",
    "Base class for data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e69418f5-db7f-475f-b205-cfd9bc314878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fromInternal(obj)\n",
    "# Converts an internal SQL object into a native Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc4abc-ad5a-4b55-b0d1-050f33c57732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a9fe8-23fc-4562-8e5a-9ad559168ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonValue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b82c26-10c5-4308-993d-1ee43881e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needConversion()\n",
    "# Does this type needs conversion between Python object and internal SQL object.\n",
    "# This is used to avoid the unnecessary conversion for ArrayType/MapType/StructType.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263f61e-c9c8-4be4-a79f-f166a50d3155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpleString()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2618e4c-0bc3-4433-97dd-d27090c630fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toInternal(obj)\n",
    "# Converts a Python object into an internal SQL object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca14bf28-7a2c-4556-8159-bc65e7b522f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classmethod typeName()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6622ca-68cf-4a25-ab92-8d3ace9aaea9",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.NullType\n",
    "Null type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2949f8b3-9370-4958-9536-66d266ed7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data type representing None, used for the types that cannot be inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adce04da-7705-4df5-91c3-ab0f2dd3ea31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbf6c4f7-2ecd-4448-b6df-9097551c8c4b",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.StringType\n",
    "String data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3633b24e-d3d7-4388-89f2-4e726c5582d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a143f49e-f144-4a8c-a192-05ef028c24ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b3485e8-712d-44f9-92f9-5fcbaae3aee9",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.BinaryType\n",
    "Binary (byte array) data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a2010-513a-4b57-92b8-3bc4ab04c4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7953e-61bc-44c3-84d4-1e06b4b0b1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ec108ee-a3ad-4baa-b9f9-a3b152acd6bc",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.BooleanType\n",
    "Boolean data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c71d03-51d5-402b-afe9-9389e3d03fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238bf443-5bae-446d-9d93-81a13879a03d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8295b6a-2108-47d5-b574-5e41bfddceaa",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.DateType\n",
    "Date (datetime.date) data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2569c5b9-bb1e-41db-9ee3-ce1200f31144",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_ORDINAL = 719163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f67e6-777f-4b01-ba32-1977bc5c74ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fromInternal(v)\n",
    "# Converts an internal SQL object into a native Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9981eb78-bd72-4c67-8e3b-c1f37d6a69a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needConversion()\n",
    "# Does this type needs conversion between Python object and internal SQL object.\n",
    "# This is used to avoid the unnecessary conversion for ArrayType/MapType/StructType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378d3ba-77d8-4cdf-8f9e-42f2c7525294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toInternal(d) \n",
    "# Converts a Python object into an internal SQL object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe4cc8-0a01-4f4b-8661-cda23503a49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3ae46aa-477e-4603-a828-1aa78aa1d58c",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.TimestampType\n",
    "Timestamp (datetime.datetime) data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9a55af-a78f-4ffa-bc4f-0106044c0942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fromInternal(ts)\n",
    "# Converts an internal SQL object into a native Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91a91e5-1c67-4c7a-8585-5def54bae2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needConversion()\n",
    "# Does this type needs conversion between Python object and internal SQL object.\n",
    "# This is used to avoid the unnecessary conversion for ArrayType/MapType/StructType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea22b13-3f89-40f5-a806-aaa777c03ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toInternal(dt)\n",
    "# Converts a Python object into an internal SQL object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f0315-7c71-484e-b3a1-ff1d37c054ce",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.DecimalType(precision=10, scale=0)\n",
    "Decimal (decimal.Decimal) data type.\n",
    "\n",
    "The DecimalType must have fixed precision (the maximum total number of digits) and scale (the number of digits on the right of dot). For example, (5, 2) can support the value from [-999.99 to 999.99].\n",
    "\n",
    "The precision can be up to 38, the scale must be less or equal to precision.\n",
    "\n",
    "When creating a DecimalType, the default precision and scale is (10, 0). When inferring schema from decimal.Decimal objects, it will be DecimalType(38, 18).\n",
    "\n",
    "Parameters: \n",
    "* precision – the maximum (i.e. total) number of digits (default: 10)\n",
    "* scale – the number of digits on right side of dot. (default: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2390f43e-e297-4702-b4e8-04b2e19b434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c64ab74-7317-4638-a9bf-c40d534baff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpleString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea41ce8-f17e-48f6-9189-e74bf0d5feab",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.DoubleType\n",
    "Double data type, representing double precision floats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29888e13-fc5f-44c0-a7ed-4993ed2228d8",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.FloatType\n",
    "Float data type, representing single precision floats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f5e6b-bb45-462a-8dd3-15caa123b55e",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.ByteType\n",
    "Byte data type, i.e. a signed integer in a single byte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a3831c6-acbf-4edb-8776-3c079959b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpleString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b86c5-a68f-4263-a33a-40068c2d2187",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.IntegerType\n",
    "Int data type, i.e. a signed 32-bit integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f6b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpleString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8871f3-34de-4a3f-bb96-93c6cb0b9732",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.LongType[source]\n",
    "Long data type, i.e. a signed 64-bit integer.\n",
    "\n",
    "If the values are beyond the range of [-9223372036854775808, 9223372036854775807], please use DecimalType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ba7f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpleString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094a140-99c2-4253-95f1-c0a3538de88f",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.ShortType\n",
    "Short data type, i.e. a signed 16-bit integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4456cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpleString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f3d29b-eeeb-4a87-9e46-a894d0bf890f",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.ArrayType(elementType, containsNull=True)\n",
    "Array data type.\n",
    "\n",
    "Parameters: \n",
    "* elementType – DataType of each element in the array.\n",
    "* containsNull – boolean, whether the array can contain null (None) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70cfae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fromInternal(obj)[source]\n",
    "# Converts an internal SQL object into a native Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd0afc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classmethod fromJson(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f17955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba1bf5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needConversion()\n",
    "# Does this type needs conversion between Python object and internal SQL object.\n",
    "# This is used to avoid the unnecessary conversion for ArrayType/MapType/StructType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0294e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpleString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f0f15f-d223-449f-9d43-87cf99a15f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toInternal(obj)[source]\n",
    "# Converts a Python object into an internal SQL object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf30ea1-f147-4d17-805c-8d867f05ad49",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.MapType(keyType, valueType, valueContainsNull=True)\n",
    "Map data type. Parameters:\n",
    "- keyType – DataType of the keys in the map.\n",
    "- valueType – DataType of the values in the map.\n",
    "- valueContainsNull – indicates whether values can contain null (None) values.\n",
    "Keys in a map data type are not allowed to be null (None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f2a2377-bc3e-4763-982d-72a119aae3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fromInternal(obj)\n",
    "# Converts an internal SQL object into a native Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d32a8-4614-41bc-9fe6-ccb670c4f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classmethod fromJson(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dce8dd-ec97-43a5-a3c6-c0ba839ece61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926189e8-1f49-43fa-8d19-4ac3559b75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needConversion()\n",
    "# Does this type needs conversion between Python object and internal SQL object.\n",
    "# This is used to avoid the unnecessary conversion for ArrayType/MapType/StructType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a17e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpleString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e07b06d-beea-4902-b7c3-6f805c95ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toInternal(obj)\n",
    "# Converts a Python object into an internal SQL object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3538c24-89d2-4479-be9f-cf6eca2b116f",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.StructField(name, dataType, nullable=True, metadata=None)\n",
    "A field in StructType.\n",
    "Parameters :\n",
    "- name – string, name of the field.\n",
    "- dataType – DataType of the field.\n",
    "- nullable – boolean, whether the field can be null (None) or not.\n",
    "- metadata – a dict from string to simple type that can be toInternald to JSON automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d883fa2-de65-40f5-86cc-99fa53c5bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fromInternal(obj)\n",
    "# Converts an internal SQL object into a native Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7545c221-ae39-43b6-bac5-2494c50ceb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classmethod fromJson(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67895b9b-cffe-476b-b4f1-abddcc18dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad0e806-ef98-498c-bd61-74ec73a932ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needConversion()\n",
    "# Does this type needs conversion between Python object and internal SQL object.\n",
    "# This is used to avoid the unnecessary conversion for ArrayType/MapType/StructType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e49ec0-45d8-4608-af22-4388ed3c3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpleString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0260b71-213f-4b72-b969-0cea802c6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toInternal(obj)\n",
    "# Converts a Python object into an internal SQL object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22d23a-2788-48e8-a3bd-6f1b17498c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# typeName()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036b3d0-07e0-4bce-ae18-3b64e45e6c4e",
   "metadata": {},
   "source": [
    "#### class pyspark.sql.types.StructType(fields=None)\n",
    "Struct type, consisting of a list of StructField.\n",
    "\n",
    "This is the data type representing a Row.\n",
    "\n",
    "Iterating a StructType will iterate over its StructFields. A contained StructField can be accessed by its name or position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5e4847-6601-4c0a-a4f4-e411a84a4446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructField('f1', StringType(), True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "struct1 = StructType([StructField(\"f1\", StringType(), True)])\n",
    "struct1[\"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92b4e965-c1cc-4378-a944-d62bfd4bcc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructField('f1', StringType(), True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd0768-d2ff-4d57-94c6-83086ca92a9e",
   "metadata": {},
   "source": [
    "##### add(field, data_type=None, nullable=True, metadata=None)\n",
    "Construct a StructType by adding new elements to it, to define the schema. The method accepts either:\n",
    "- A single parameter which is a StructField object.\n",
    "- Between 2 and 4 parameters as (name, data_type, nullable (optional), metadata(optional). The data_type parameter may be either a String or a DataType object.\n",
    "\n",
    "Parameters:\n",
    "* field – Either the name of the field or a StructField object\n",
    "* data_type – If present, the DataType of the StructField to create\n",
    "* nullable – Whether the field to add should be nullable (default True)\n",
    "* metadata – Any additional metadata (default None)\n",
    "\n",
    "Returns: a new updated StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "794562b2-f5ef-4146-bbd8-bb6b6016b4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct1 = StructType().add(\"f1\", StringType(), True).add(\"f2\", StringType(), True, None)\n",
    "struct2 = StructType([StructField(\"f1\", StringType(), True), StructField(\"f2\", StringType(), True, None)])\n",
    "struct1 == struct2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae367536-b923-46ff-bd3f-70668175a7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct1 = StructType().add(StructField(\"f1\", StringType(), True))\n",
    "struct2 = StructType([StructField(\"f1\", StringType(), True)])\n",
    "struct1 == struct2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3311dd0-6cbf-4dd6-97ac-0d4876a55e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct1 = StructType().add(\"f1\", \"string\", True)\n",
    "struct2 = StructType([StructField(\"f1\", StringType(), True)])\n",
    "struct1 == struct2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54e336bc-df1b-496f-872f-257a775884db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fieldNames()\n",
    "# Returns all field names in a list.\n",
    "struct = StructType([StructField(\"f1\", StringType(), True)])\n",
    "struct.fieldNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc6e1d-cf0a-462c-ab2e-ea84340ba92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fromInternal(obj)\n",
    "# Converts an internal SQL object into a native Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1da6f-2034-415e-bfe5-dd6a5477390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classmethod fromJson(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e586325d-4f11-4fed-bbf6-acfa83e42c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083d7e68-53f4-4ecf-b02b-62a39aad1add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needConversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf86b7fc-52ad-4a40-95b9-6be8eb36ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpleString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eed08b-ea15-4a1c-a58e-48e0b6748a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toInternal(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e08956-3f34-4679-b13c-394fe953914a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
